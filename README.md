# ğŸ›ï¸ Customer Segmentation & Clustering Pipeline

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red)
![Scikit-Learn](https://img.shields.io/badge/ML-KMeans-orange)

## ğŸ“Œ Sobre o Projeto

Este projeto consiste em uma soluÃ§Ã£o *End-to-End* de CiÃªncia e Engenharia de Dados para segmentaÃ§Ã£o de clientes de um E-commerce internacional. 

O objetivo foi transformar dados transacionais brutos em inteligÃªncia de negÃ³cio, identificando perfis de consumo atravÃ©s da metodologia **RFM (RecÃªncia, FrequÃªncia e MonetarizaÃ§Ã£o)** e agrupamento com algoritmo **K-Means**. A entrega final Ã© uma aplicaÃ§Ã£o Web onde o time de Marketing pode fazer upload de novos dados e receber a classificaÃ§Ã£o automÃ¡tica dos clientes (VIPs, Leais, Em Risco, etc.).

## ğŸ—ï¸ Arquitetura e Tecnologias

O projeto foi estruturado simulando um cenÃ¡rio real de produÃ§Ã£o:

* **Coleta de Dados:** Script automatizado para download de dados via API do Kaggle.
* **ETL (Extract, Transform, Load):** Limpeza de dados, tratamento de nulos/devoluÃ§Ãµes e engenharia de atributos (CriaÃ§Ã£o da tabela RFM) utilizando **Pandas**.
* **Machine Learning:**
    * PadronizaÃ§Ã£o de dados com `StandardScaler`.
    * ClusterizaÃ§Ã£o com **K-Means**.
    * OtimizaÃ§Ã£o de hiperparÃ¢metros (MÃ©todo do Cotovelo e Silhouette Score).
* **Deploy / AplicaÃ§Ã£o:** Interface interativa desenvolvida em **Streamlit**.

## ğŸ“Š Resultados e Perfis Identificados

O modelo identificou 4 clusters distintos de comportamento:

| Perfil | CaracterÃ­sticas | EstratÃ©gia Recomendada |
| :--- | :--- | :--- |
| **ğŸ† VIP (Ouro)** | Alto ticket, alta frequÃªncia e compra recente. | Atendimento exclusivo e retenÃ§Ã£o. |
| **ğŸ¥ˆ Leais (Prata)** | Compram com regularidade e bom ticket. | Programas de fidelidade e Cross-sell. |
| **ğŸ¥‰ Casuais (Bronze)** | Ticket baixo e compras esporÃ¡dicas. | Incentivos de volume (cupons). |
| **âš ï¸ Inativos (Churn)** | NÃ£o compram hÃ¡ muito tempo (+200 dias). | Campanhas de reativaÃ§Ã£o ou limpeza de base. |

## ğŸš€ Como Executar o Projeto

### PrÃ©-requisitos
* Python 3.x
* Conta no Kaggle (para baixar o dataset original)

### 1. InstalaÃ§Ã£o
Clone este repositÃ³rio e instale as dependÃªncias:

```bash
git clone [https://github.com/SEU-USUARIO/NOME-DO-REPO.git](https://github.com/SEU-USUARIO/NOME-DO-REPO.git)
cd NOME-DO-REPO
pip install -r requirements.txt

### 2. Coleta dos Dados (AutomÃ¡tica)
Para baixar a base de dados original ("E-Commerce Data" da UCI), vocÃª precisa configurar sua API do Kaggle:

* Gere seu token no site do Kaggle (`kaggle.json`).
* Coloque o arquivo na pasta padrÃ£o (`~/.kaggle/` ou `C:\Users\Voce\.kaggle\`).
* Execute o Jupyter Notebook `01_analise_exploratoria.ipynb`. A primeira cÃ©lula farÃ¡ o download automÃ¡tico.

### 3. Rodando a AplicaÃ§Ã£o Web
Com os arquivos de modelo (`.pkl`) gerados pelo notebook (ou jÃ¡ presentes no repo), execute:

```bash
streamlit run app.py

O navegador abrirÃ¡ automaticamente a interface de segmentaÃ§Ã£o.

### 4. Testando com Novos Dados
Para simular novos dados de entrada, execute o script gerador:

```bash
python gerar_teste.py

Isso criarÃ¡ o arquivo `novas_entradas.csv`, que pode ser carregado na aplicaÃ§Ã£o Streamlit para validaÃ§Ã£o.

## ğŸ“ˆ Aprendizados e Desafios

* **Tratamento de Dados Transacionais:** O maior desafio foi converter um log de vendas (transacional) em uma visÃ£o Ãºnica por cliente (analÃ­tica) usando agregaÃ§Ãµes complexas.
* **ValidaÃ§Ã£o de Clusters:** O uso conjunto da InÃ©rcia e Silhouette Score foi fundamental para decidir entre 2 ou 4 clusters, equilibrando matemÃ¡tica e utilidade de negÃ³cio.
* **Engenharia de Software:** A estruturaÃ§Ã£o do `app.py` exigiu encapsular o prÃ©-processamento em funÃ§Ãµes para garantir que novos dados passem pelo mesmo tratamento do treino.
