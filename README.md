# üõçÔ∏è Customer Segmentation & Clustering Pipeline

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Streamlit](https://img.shields.io/badge/Streamlit-App-red)
![Scikit-Learn](https://img.shields.io/badge/ML-KMeans-orange)

## üìå Sobre o Projeto

Este projeto consiste em uma solu√ß√£o *End-to-End* de Ci√™ncia e Engenharia de Dados para segmenta√ß√£o de clientes de um E-commerce internacional. 

O objetivo foi transformar dados transacionais brutos em intelig√™ncia de neg√≥cio, identificando perfis de consumo atrav√©s da metodologia **RFM (Rec√™ncia, Frequ√™ncia e Monetariza√ß√£o)** e agrupamento com algoritmo **K-Means**. A entrega final √© uma aplica√ß√£o Web onde o time de Marketing pode fazer upload de novos dados e receber a classifica√ß√£o autom√°tica dos clientes (VIPs, Leais, Em Risco, etc.).

## üèóÔ∏è Arquitetura e Tecnologias

O projeto foi estruturado simulando um cen√°rio real de produ√ß√£o:

* **Coleta de Dados:** Script automatizado para download de dados via API do Kaggle.
* **ETL (Extract, Transform, Load):** Limpeza de dados, tratamento de nulos/devolu√ß√µes e engenharia de atributos (Cria√ß√£o da tabela RFM) utilizando **Pandas**.
* **Machine Learning:**
    * Padroniza√ß√£o de dados com `StandardScaler`.
    * Clusteriza√ß√£o com **K-Means**.
    * Otimiza√ß√£o de hiperpar√¢metros (M√©todo do Cotovelo e Silhouette Score).
* **Deploy / Aplica√ß√£o:** Interface interativa desenvolvida em **Streamlit**.

## üìä Resultados e Perfis Identificados

O modelo identificou 4 clusters distintos de comportamento:

| Perfil | Caracter√≠sticas | Estrat√©gia Recomendada |
| :--- | :--- | :--- |
| **üèÜ VIP (Ouro)** | Alto ticket, alta frequ√™ncia e compra recente. | Atendimento exclusivo e reten√ß√£o. |
| **ü•à Leais (Prata)** | Compram com regularidade e bom ticket. | Programas de fidelidade e Cross-sell. |
| **ü•â Casuais (Bronze)** | Ticket baixo e compras espor√°dicas. | Incentivos de volume (cupons). |
| **‚ö†Ô∏è Inativos (Churn)** | N√£o compram h√° muito tempo (+200 dias). | Campanhas de reativa√ß√£o ou limpeza de base. |

##  Como Executar o Projeto

### Pr√©-requisitos
* Python 3.x
* Conta no Kaggle (para baixar o dataset original)

### 1. Instala√ß√£o
Clone este reposit√≥rio e instale as depend√™ncias:

```bash
git clone [https://github.com/nayarasudariodiniz/clusterizacao_segmentacao_clientes.git](https://github.com/nayarasudariodiniz/clusterizacao_segmentacao_clientes.git)
cd NOME-DO-REPO
pip install -r requirements.txt
```
### 2. Coleta dos Dados (Autom√°tica)
Para baixar a base de dados original ("E-Commerce Data" da UCI), voc√™ precisa configurar sua API do Kaggle:

* Gere seu token no site do Kaggle (`kaggle.json`).
* Coloque o arquivo na pasta padr√£o (`~/.kaggle/` ou `C:\Users\Voce\.kaggle\`).
* Execute o Jupyter Notebook `01_analise_exploratoria.ipynb`. A primeira c√©lula far√° o download autom√°tico.

### 3. Rodando a Aplica√ß√£o Web
Com os arquivos de modelo (`.pkl`) gerados pelo notebook (ou j√° presentes no repo), execute:

```bash
streamlit run app.py
```

O navegador abrir√° automaticamente a interface de segmenta√ß√£o.

### 4. Testando com Novos Dados
Para simular novos dados de entrada, execute o script gerador:

```bash
python gerar_teste.py
```

Isso criar√° o arquivo `novas_entradas.csv`, que pode ser carregado na aplica√ß√£o Streamlit para valida√ß√£o.

## üìà Aprendizados e Desafios

* **Tratamento de Dados Transacionais:** O maior desafio foi converter um log de vendas (transacional) em uma vis√£o √∫nica por cliente (anal√≠tica) usando agrega√ß√µes complexas.
* **Valida√ß√£o de Clusters:** O uso conjunto da In√©rcia e Silhouette Score foi fundamental para decidir entre 2 ou 4 clusters, equilibrando matem√°tica e utilidade de neg√≥cio.
* **Engenharia de Software:** A estrutura√ß√£o do `app.py` exigiu encapsular o pr√©-processamento em fun√ß√µes para garantir que novos dados passem pelo mesmo tratamento do treino.
